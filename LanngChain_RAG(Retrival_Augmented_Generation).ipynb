{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedsaqib122/LangChain-Hello-World/blob/main/LanngChain_RAG(Retrival_Augmented_Generation).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LangChainRag**"
      ],
      "metadata": {
        "id": "C39WlrjSuN5l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vPz7c_Jjn2a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cccca1b8-9a9e-42bb-b80e-2af09263071f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -Uq Langchain-pinecone Langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "PINECONE_API_KEY = userdata.get('PINECONE_API_KEY')\n",
        "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n"
      ],
      "metadata": {
        "id": "69x1AudFu2BQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "\n",
        "index_name = \"langchain-rag-project\"\n",
        "\n",
        "# Check if the index exists\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=768,\n",
        "        metric=\"cosine\",\n",
        "        spec=pinecone.ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "else:\n",
        "    print(f\"Index '{index_name}' already exists.\")\n",
        "\n",
        "# Connect to the existing index\n",
        "index = pc.Index(index_name)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xineGVjL33Le"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "os.environ['GOOGLE_API_KEY']= userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "vector = embeddings.embed_query(\"hello, world!\")\n",
        "vector[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLX5d0rh65kQ",
        "outputId": "9bf4b260-ab97-43cf-8c15-41141a75ccbe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05168594419956207,\n",
              " -0.030764883384108543,\n",
              " -0.03062233328819275,\n",
              " -0.02802734263241291,\n",
              " 0.01813093200325966]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "vector_store = PineconeVectorStore( index=index, embedding=embeddings,)"
      ],
      "metadata": {
        "id": "ADf6IYse42OQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dummy Documents\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocalate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]\n"
      ],
      "metadata": {
        "id": "9I8K5tmd9bpF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
        "\n",
        "vector_store.add_documents(documents=documents, ids=uuids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "738dLLTW9vCl",
        "outputId": "4208d616-3fad-44e0-dadb-d8787d05df03"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['16c60848-83d6-4d47-9c8f-1dddefc829f0',\n",
              " '5a1eca04-8537-4042-aefa-8429be0613a8',\n",
              " '628ee9ff-1e0f-4637-a109-41bc39743a97',\n",
              " 'a638359b-32e0-43fa-99b2-cf7267d2dec1',\n",
              " '7f6b35ac-4069-4b5b-b070-18a3c611d1ba',\n",
              " 'f3e0149b-3c7e-43c2-901d-c355d7ab55e6',\n",
              " '01ec7d27-2807-4cdc-82df-88194d8df27c',\n",
              " 'f40be8bd-9770-4d80-9ec2-94befae5f9dc',\n",
              " 'cfe3b635-bf2a-4fc0-9d85-25635ba182a4',\n",
              " '20e01c04-5f33-40e9-922a-e89b37660898']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = vector_store.similarity_search(\n",
        "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
        "     k=2.,\n",
        "    filter={\"source\": \"tweet\"},\n",
        "\n",
        ")\n",
        "for res in results:\n",
        "    print(f\"* {res.page_content} [{res.metadata}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsmYAXSA_q-5",
        "outputId": "7d3936d8-1c91-4af7-9ac6-cde138bebacb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n",
            "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = vector_store.similarity_search_with_score(\n",
        "    \"Will it be hot tomorrow?\", k=5, filter={\"source\": \"news\"}\n",
        ")\n",
        "for res, score in results:\n",
        "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbRI6bLzDjcy",
        "outputId": "76ad5229-43ab-4b66-ac76-117aac5e3a57"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* [SIM=0.667716] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]\n",
            "* [SIM=0.533720] The stock market is down 500 points today due to fears of a recession. [{'source': 'news'}]\n",
            "* [SIM=0.474582] Robbers broke into the city bank and stole $1 million in cash. [{'source': 'news'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2\n",
        ")"
      ],
      "metadata": {
        "id": "dDd6Syy_N82p"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def question_answering(question: str):\n",
        "  results = vector_store.similarity_search(question, k=2)\n",
        "\n",
        "  final_answer = llm.invoke(f\"ANSWER THIS USER QUERRY:{question} USING THE CONTEXT:{results}\")\n",
        "  return final_answer"
      ],
      "metadata": {
        "id": "UT_DfRsRM_HG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask_a_question = input(\"Ask a question: \")\n",
        "answer = question_answering(ask_a_question)\n",
        "print(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoliC_N3PmnO",
        "outputId": "be06a9ec-741f-4e0b-9e8a-55cd96d03a3d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ask a question: what is the capital of pakistan\n",
            "content='This question cannot be answered from the given source.  The provided text does not contain any information about the capital of Pakistan.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-a66edcb7-34aa-45be-a728-50c2f2957c00-0' usage_metadata={'input_tokens': 147, 'output_tokens': 26, 'total_tokens': 173, 'input_token_details': {'cache_read': 0}}\n"
          ]
        }
      ]
    }
  ]
}